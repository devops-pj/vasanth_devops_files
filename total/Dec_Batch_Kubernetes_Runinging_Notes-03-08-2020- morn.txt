01-Mar-2020 6:00 AM
=========== 

Containerization
Docker
Rocket


Cotainer Orchestration Tools
Docker Swarm

Kubernetes Can Orchestrate Docker or Rocker(rkt) containers also.

OpenShift

1) Dynamic Scaling.

2) HelathCheck(Liveness Probe & Readyness Probe) On Applications/Containers. If health check fails Contianers will be killed and will create new containers.

3) Kubernetes is  availble as a PAAS in most of the cloud providers.
    EKS --> Elastic Kuberetes Service --> AWS
    AKS --> Azure Kubernetes Service --> Azure
    GKE --> Google Kubernetes Engine --> Google Cloud
	
4) Security.	


Kubernetes Setup:

Types of Kubernetes Clusters.

  1) Self Managed Kubernetes Cluster.
  
     minikube --> Using minikube We can set up single node k8's 				  Cluster.
	 Kubeadm  --> We can setup multi node k8's cluster.
	 
  
  2) Cloud Managed Services(PAAS).
    
    EKS --> Elastic Kuberetes Service --> AWS
    AKS --> Azure Kubernetes Service --> Azure
    GKE --> Google Kubernetes Engine --> Google Cloud

    KOPS --> Kubernetes Operations using which we can setup k8s in 			 AWS.

01-Mar-2020 7:00 PM

Kubernetes Objects:

POD

Replication Controller

Replica Set

DaemonSet

Deployment

Service

Kubenetes Manifest

POD

Sample POD Mainifest

# Single Container POD
apiVersion: v1
kind: Pod
metadata:
  name:  <PODName>
  labels:
    <labelKey>: <labelValue> 
spec:
  containers:
  - name: <nameOftheCotnainer>
    image: <imageName>
	ports:
	- containerPort: <portNumberOfContainer>



Ex:

apiVersion: v1
kind: Pod
metadata:
  name: javawebapppod
  labels:
     app: javawebapp
spec:
  containers:
  - name: javawebappcontainer
    image: dockerhandson/java-web-app
	ports:
	- containerPort: 8080
		 

# Multi Container POD
apiVersion: v1
kind: Pod
metadata:
  name:  <PODName>
  labels:
    <labelKey>: <labelValue> 
spec:
  containers:
  - name: <nameOftheCotnainer>
    image: <imageName>
	ports:
	- containerPort: <portNumberOfContainer>
  - name: <nameOftheCotnainer>
    image: <imageName>
    ports:
    - containerPort: <portNumberOfContainer>	



Service Manifest

apiVersion: v1
kind: Service
metadata:
  name: <ServiceName>
spec:
  selector:
    <PodLabelKey>: <PodLabelValue>
  type: <servcieType>  # ClusterIP/NodePort/LoadBalancer
  ports:
  - port: <sevicePort>
    targetPort: <containerPortOfPod>
	nodePort: <nodePort> # This Applicable only of type is NodePort .Random Port Number 	which is availble in Kubertes servers(30000-32767)

With in Cluster ClusterIP
==========================
apiVersion: v1
kind: Service
metadata:
  name: javawebapp
spec:
  selector:
     app: javawebapp
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8080

Out Cluster Node Port
====================
apiVersion: v1
kind: Service
metadata:
  name: javawebapp
spec:
  selector:
     app: javawebapp
  type: NodePort
  ports:
  - port: 80
    targetPort: 8080
	nodePort: 30033 # This Optional if u don't mention nodePort.Kuberetes will assign.


07:03-2020 6:00 AM


# Single Container POD
apiVersion: v1
kind: Pod
metadata:
  name:  <PODName>
  labels:
    <labelKey>: <labelValue> 
spec:
  containers:
  - name: <nameOftheCotnainer>
    image: <imageName>
	ports:
	- containerPort: <portNumberOfContainer>



# Replication Controller
apiVersion: v1
kind: ReplicationController
metadata:
  name: <rcName>
spec:
  replicas: <NoOfReplicas>
  selector:
    <podLabelKey> : <Value>
  template:
    metadata:
       name: <PodName>
	   labels:
	     <podLabelKey>: <value>
    spec:
	  containers:
	  - name: <nameOfTheContainer>
	    image: <ImageName>
		ports:
		- containerPort: <PortOfContainer>
Example
		
apiVersion: v1
kind: ReplicationController
metadata:
  name: javawebapprc
spec:
  replicas: 2
  selector:
    app: javawebapp
  template:
    metadata:
      #name: javawebapppod
      labels:
        app: javawebapp
    spec:
     containers:
     - name: javawebappcontainer
       image: dockerhandson/java-web-app
       ports:
       - containerPort: 8080

--- 
apiVersion: v1
kind: Service
metadata:
  name: javawebapp
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080

commands:

kubectl apply -f <rcFileName.yml>
kubectl get rc
kubectl scale rc <rcName> --replicas <noOfReplicas>
kubectl describe rc <rcName>
kubectl delete rc <rcName> 

			
Difference b/w RC & RS ?
Rs is next genration of RC.Only difference is in selector support.Replication Controller Supports only Equality Based Selector.Where as RS(ReplicaSet) supports equality based & set based selectors.

# Replication Set
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: <rcName>
spec:
  replicas: <NoOfReplicas>
  selector:
    matchLabels:
      <podLabelKey> : <Value>
  template:
    metadata:
       name: <PodName>
	   labels:
	     <podLabelKey>: <value>
    spec:
	  containers:
	  - name: <nameOfTheContainer>
	    image: <ImageName>
		ports:
		- containerPort: <PortOfContainer>
    
    
# Replica Set Example

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: javawebapprs
spec:
  replicas: 2
  selector:
    matchLabels:
      app: javawebapp  
  template:
    metadata:
      #name: javawebapppod
      labels:
        app: javawebapp
    spec:
     containers:
     - name: javawebappcontainer
       image: dockerhandson/java-web-app
       ports:
       - containerPort: 8080

--- 
apiVersion: v1
kind: Service
metadata:
  name: javawebapp
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080  
	

commands:

kubectl apply -f <rsFileName.yml>
kubectl get rs
kubectl scale rs <rcName> --replicas <noOfReplicas>
kubectl describe rs <rcName>
kubectl delete rs <rcName> 
	
# DaemonSet 
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: <rcName>
spec:
  selector:
    matchLabels:
      <podLabelKey> : <Value>
  template:
    metadata:
       name: <PodName>
	   labels:
	     <podLabelKey>: <value>
    spec:
	  containers:
	  - name: <nameOfTheContainer>
	    image: <ImageName>
		ports:
		- containerPort: <PortOfContainer>		

# DaemonSet Example
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: javawebappds
spec:
  selector:
    matchLabels:
      app: javawebapp  
  template:
    metadata:
      #name: javawebapppod
      labels:
        app: javawebapp
    spec:
     containers:
     - name: javawebappcontainer
       image: dockerhandson/java-web-app
       ports:
       - containerPort: 8080

--- 
apiVersion: v1
kind: Service
metadata:
  name: javawebapp
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080

commands:

kubectl apply -f <dsFileName.yml>
kubectl get ds
kubectl describe ds <rcName>
kubectl delete ds <rcName> 


07:03-2020 7:00 PM
# Deployment Recreate

apiVersion: apps/v1
kind: Deployment
metadata:
  name: javawebappdeployment
spec:
  replicas: 2
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: javawebapp  
  template:
    metadata:
      #name: javawebapppod
      labels:
        app: javawebapp
    spec:
     containers:
     - name: javawebappcontainer
       image: dockerhandson/java-web-app:2
       ports:
       - containerPort: 8080

--- 
apiVersion: v1
kind: Service
metadata:
  name: javawebapp
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080 
	

# Deployment Rolling Update

apiVersion: apps/v1
kind: Deployment
metadata:
  name: javawebappdeployment
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  minReadySeconds: 30    
  selector:
    matchLabels:
      app: javawebapp  
  template:
    metadata:
      #name: javawebapppod
      labels:
        app: javawebapp
    spec:
     containers:
     - name: javawebappcontainer
       image: dockerhandson/java-web-app:2
       ports:
       - containerPort: 8080

--- 
apiVersion: v1
kind: Service
metadata:
  name: javawebapp
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080 	
	

Commands:
=========

kubectl scale deployment [DEPLOYMENT_NAME] --replicas [NUMBER_OF_REPLICAS]
kubectl rollout status deployment <DEPLOYMENT_NAME>
kubectl get deployment
# Update Image for your application using command instead. If dont want use below command you can update in yml then apply.
kubectl set image deployment <DEPLOYMENT_NAME> <CONTAINER_NAME>=<ImageWithVersion> --record 
kubectl get replicaset
kubectl rollout history deployment <DEPLOYMENT_NAME>
kubectl rollout history deployment <DEPLOYMENT_NAME> --revision=1
kubectl rollout undo deployment <DEPLOYMENT_NAME> --to-revision=1


# Spring boot app rc & service

apiVersion: v1
kind: ReplicationController
metadata:
  labels:
    name: springboot
  name: spring-controller
spec:
  replicas: 2
  template:
    metadata:
      labels:
        name: springboot
    spec:
      containers:
      - image: dockerhandson/spring-boot-mongo:latest
        name: springboot
        ports:
        - name: springboot
          containerPort: 8080
---
# Node Port Service
apiVersion: v1
kind: Service
metadata:
  labels:
    name: springboot
  name: springboot
spec:
  type: NodePort
  ports:
    - port: 8080
      targetPort: 8080
  selector:
    name: springboot





# Mongo rc & service with out volumes

apiVersion: v1
kind: ReplicationController
metadata:
  name: mongo-controller
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: mongo
    spec:
      containers:
      - image: mongo
        name: mongo
        ports:
        - name: mongo
          containerPort: 27017
...		 
---
# Mongo Node Port RC
apiVersion: v1
kind: Service
metadata:
  labels:
    name: mongo
  name: mongo
spec:
  type: ClusterIP
  ports:
    - port: 27017
      targetPort: 27017
  selector:
    name: mongo
	
	
	
08-03-2020 6:00 AM
==================	
	
File: mongo_rc_hostpath_directref.yml	
---
# Mongo host path rc Direct Reference
apiVersion: v1
kind: ReplicationController
metadata:
  name: mongo-controller
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: mongo
    spec:
      containers:
      - image: mongo
        name: mongo
        ports:
        - name: mongo
          containerPort: 27017
        volumeMounts:
        - name: mongodbvolume
          mountPath: /data/db      
      volumes:
      - name: mongodbvolume
        hostPath:
          path: /tmp/mongobkp    
...		 
---
# Mongo Node Port RC
apiVersion: v1
kind: Service
metadata:
  labels:
    name: mongo
  name: mongo
spec:
  type: ClusterIP
  ports:
    - port: 27017
      targetPort: 27017
  selector:
    name: mongo
...	
	

File: mongo_rc_nfs_directref.yml		
	
---
# Mongo nfs rc
apiVersion: v1
kind: ReplicationController
metadata:
  name: mongo-controller
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: mongo
    spec:
      containers:
      - image: mongo
        name: mongo
        ports:
        - name: mongo
          containerPort: 27017
        volumeMounts:
        - name: mongodbvolume
          mountPath: /data/db      
      volumes:
      - name: mongodbvolume
        nfs:
          server: 172.31.47.47      
          path: /mnt/share    
...		 
---
# Mongo Node Port RC
apiVersion: v1
kind: Service
metadata:
  labels:
    name: mongo
  name: mongo
spec:
  type: ClusterIP
  ports:
    - port: 27017
      targetPort: 27017
  selector:
    name: mongo
...		


PersistentVolume (PV)

An API volume object that represents a storage location that lives in your Kubernetes cluster. A PV is implemented as a Volume plugin—it abstracts the details of the storage implementation (such as NFS or iSCSI communication), from the storage consumer. The main feature of a PV is that it has an independent life cycle, and it continues to live when the pods accessing it have shut down.

Volume infomation will be persisted in kubernetes cluster.PV Can be create for any volume type which is supported by Kubernetes.
		 
		  hostpath
		  nfs
		  awsElasticBlockStore
		  azureDisk
		  azureFile ..etc

Persistant volumes can be provisend in two ways. Static Provisining,Dynamic Provising.
		 
		
PersistentVolumeClaim (PVC)
		
This is a request sent by a Kubernetes node for storage. The claim can include specific storage parameters required by the application—for example an amount of storage, or a specific type of access (read/write, read-only, etc.). Kubernetes looks for a PV that meets the criteria defined in the user’s PVC, and if there is one, it matches claim to PV. This is called binding. You can also configure the cluster to dynamically provision a PV for a claim.		 
		 



PV & PVC AccessModes

The access modes are:

ReadWriteOnce – the volume can be mounted as read-write by a single node
ReadOnlyMany – the volume can be mounted read-only by many nodes
ReadWriteMany – the volume can be mounted as read-write by many nodes

In the CLI, the access modes are abbreviated to:
RWO - ReadWriteOnce
ROX - ReadOnlyMany
RWX - ReadWriteMany



File: hostpath_pv.yml 

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-hostpath
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/tmp/mongobkp"

File: hostpath_pvc.yml 	

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-hostpath
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Mi	
	  

File: mongo_hostpath_pvc.yml 

# Mongo pvc with rc
apiVersion: v1
kind: ReplicationController
metadata:
  name: mongo-controller
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: mongo
    spec:
      containers:
      - image: mongo
        name: mongo
        ports:
        - name: mongo
          containerPort: 27017
        volumeMounts:
        - name: mongodbvolume
          mountPath: /data/db      
      volumes:
      - name: mongodbvolume
        persistentVolumeClaim:
          claimName: pvc-hostpath  
...		 
---
# Mongo Node Port RC
apiVersion: v1
kind: Service
metadata:
  labels:
    name: mongo
  name: mongo
spec:
  type: ClusterIP
  ports:
    - port: 27017
      targetPort: 27017
  selector:
    name: mongo
...	

File: nfs_pv.yml

apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs
  labels:
    type: nfs
spec:
  storageClassName: manual
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  nfs:
    server: 172.31.47.47     
    path: "/mnt/share"

File: nfs_pvc.yml
	
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-nfs-pv1
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 500Mi	

File: mongo_nfs_pvc.yml	  
---
# Mongo pvc  rc
apiVersion: v1
kind: ReplicationController
metadata:
  name: mongo-controller
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: mongo
    spec:
      containers:
      - image: mongo
        name: mongo
        ports:
        - name: mongo
          containerPort: 27017
        volumeMounts:
        - name: mongodbvolume
          mountPath: /data/db      
      volumes:
      - name: mongodbvolume
        persistentVolumeClaim:
          claimName: pvc-nfs-pv1
...		 
---
# Mongo Node Port RC
apiVersion: v1
kind: Service
metadata:
  labels:
    name: mongo
  name: mongo
spec:
  type: ClusterIP
  ports:
    - port: 27017
      targetPort: 27017
  selector:
    name: mongo
...	

Commands:
==========

kubectl get pv
kubectl get pvc

kubectl describe pv <pvName>

kubectl describe pvc <pvcName>
